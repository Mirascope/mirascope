interactions:
- request:
    body: '{"max_tokens":1024,"messages":[{"role":"user","content":"Who created you?"}],"model":"claude-sonnet-4-0","stream":true}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      anthropic-version:
      - '2023-06-01'
      connection:
      - keep-alive
      content-length:
      - '119'
      content-type:
      - application/json
      host:
      - api.anthropic.com
      user-agent:
      - AsyncAnthropic/Python 0.64.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 0.64.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.10.16
      x-stainless-stream-helper:
      - messages
      x-stainless-timeout:
      - NOT_GIVEN
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: 'event: message_start

        data: {"type":"message_start","message":{"id":"msg_019Hs7mhcRxYBPcYDJ5WxvQ4","type":"message","role":"assistant","model":"claude-sonnet-4-20250514","content":[],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard"}}   }


        event: content_block_start

        data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}              }


        event: content_block_delta

        data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"I
        was created by Anthropic."}           }


        event: content_block_stop

        data: {"type":"content_block_stop","index":0             }


        event: message_delta

        data: {"type":"message_delta","delta":{"stop_reason":"end_turn","stop_sequence":null},"usage":{"input_tokens":11,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":11}        }


        event: message_stop

        data: {"type":"message_stop"        }


        '
    headers:
      CF-RAY:
      - 987825873b02868e-SEA
      Cache-Control:
      - no-cache
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream; charset=utf-8
      Date:
      - Wed, 01 Oct 2025 01:22:02 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-organization-id:
      - 217a607f-ed5e-40af-8a7d-f83ed52d59d6
      anthropic-ratelimit-input-tokens-limit:
      - '2000000'
      anthropic-ratelimit-input-tokens-remaining:
      - '2000000'
      anthropic-ratelimit-input-tokens-reset:
      - '2025-10-01T01:22:01Z'
      anthropic-ratelimit-output-tokens-limit:
      - '400000'
      anthropic-ratelimit-output-tokens-remaining:
      - '400000'
      anthropic-ratelimit-output-tokens-reset:
      - '2025-10-01T01:22:01Z'
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2025-10-01T01:22:01Z'
      anthropic-ratelimit-tokens-limit:
      - '2400000'
      anthropic-ratelimit-tokens-remaining:
      - '2400000'
      anthropic-ratelimit-tokens-reset:
      - '2025-10-01T01:22:01Z'
      cf-cache-status:
      - DYNAMIC
      request-id:
      - req_011CTfbtgzozx12nSu8cA3Ah
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      via:
      - 1.1 google
      x-envoy-upstream-service-time:
      - '827'
    status:
      code: 200
      message: OK
- request:
    body: '{"contents": [{"parts": [{"text": "Who created you?"}], "role": "user"},
      {"parts": [{"text": "I was created by Anthropic."}], "role": "model"}, {"parts":
      [{"text": "Can you double-check that?"}], "role": "user"}]}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '213'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - google-genai-sdk/1.31.0 gl-python/3.10.16
      x-goog-api-client:
      - google-genai-sdk/1.31.0 gl-python/3.10.16
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse
  response:
    body:
      string: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"You
        are absolutely right to ask me to double-check! My apologies for that error.\\n\\nI
        am a large language model, trained by **Google**.\"}],\"role\": \"model\"},\"finishReason\":
        \"STOP\",\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\": 21,\"candidatesTokenCount\":
        31,\"totalTokenCount\": 229,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\":
        21}],\"thoughtsTokenCount\": 177},\"modelVersion\": \"gemini-2.5-flash\",\"responseId\":
        \"OoLcaNCjOc2sqtsP5LWGqQw\"}\r\n\r\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Disposition:
      - attachment
      Content-Type:
      - text/event-stream
      Date:
      - Wed, 01 Oct 2025 01:22:04 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=1526
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
version: 1
