interactions:
- request:
    body: '{"contents": [{"parts": [{"text": "Who created you?"}], "role": "user"}]}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '73'
      Content-Type:
      - application/json
      Host:
      - generativelanguage.googleapis.com
      user-agent:
      - google-genai-sdk/1.48.0 gl-python/3.13.3
      x-goog-api-client:
      - google-genai-sdk/1.48.0 gl-python/3.13.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAC/2WQQU/DMAyF7/0VUc7rtBUNAbcJENoBUUYZA8TBUK+NliYlcaVN0/47abt2qegh
        svxen+3vEDDGf0ClIgVCy2/Yp+swdmjeWtOKUJETupZrlmDo7G2/g1c7C+Gu/okvGBQMmASToXtV
        VoErCp2iHDEyIBSm7HvPHrTOJI65l3Ls66/RebbREuvgJqKzHzsD3wglbL5EsFrVtpfkKea9KlSK
        O9eeBN2AJppX1m31iASOAvS38tLooqREb1Hd6qqhMGuzPGYDeTo96aQJ5ECKouvRv1h754YK6cP0
        OLsbQQra14ck9+uEexxosFXHIfBwccp1leU03DCaXgQnYC3DFRorWlgZFg5fGI1n4UaCzZt53KAt
        tbK4SGvPavl8Be9v8xgvs0m4jX8/krCav/LgGPwBga/wdE0CAAA=
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 12 Dec 2025 13:10:46 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=2051
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Who created you?"}, {"role":
      "assistant", "content": "I am a large language model, trained by Google."},
      {"role": "user", "content": "Can you double-check that?"}], "model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "stream": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '286'
      Content-Type:
      - application/json
      User-Agent:
      - Together/v1 PythonBindings/1.5.31
      X-Together-Client-User-Agent:
      - '{"bindings_version": "1.5.31", "httplib": "requests", "lang": "python", "lang_version":
        "3.13.3", "platform": "macOS-15.1.1-arm64-arm-64bit-Mach-O", "publisher":
        "together", "uname": "Darwin 24.1.0 Darwin Kernel Version 24.1.0: Thu Oct
        10 21:03:11 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T6020 arm64 arm"}'
    method: POST
    uri: https://api.together.xyz/v1/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"oNvArbw-zqrih-9acd76baed3ee37a\",\n  \"object\": \"chat.completion\",\n
        \ \"created\": 1765545046,\n  \"model\": \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n
        \ \"metadata\": {\n    \"weight_version\": \"default\"\n  },\n  \"prompt\":
        [],\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n
        \       \"role\": \"assistant\",\n        \"content\": \"I was created by
        Meta, not Google. I'm a product of Meta's Llama model, designed to assist
        and communicate with users.\",\n        \"tool_calls\": [],\n        \"reasoning\":
        null\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\",\n
        \     \"seed\": null\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
        42,\n    \"total_tokens\": 70,\n    \"completion_tokens\": 28\n  }\n}"
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 9acd76baed3ee37a-NRT
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Fri, 12 Dec 2025 13:10:46 GMT
      ETag:
      - W/"2be-8Yqvu4SHK8VbbtzBkggwhpuDChc"
      Retry-After:
      - '2'
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=15552000; includeSubDomains
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      alt-svc:
      - h3=":443"; ma=86400
      x-amzn-trace-id:
      - fcccdde1-7aba-49bf-9afc-5b7ad97ffe57-noamzn
      x-api-call-end:
      - '2025-12-12T13:10:46.682Z'
      x-api-call-start:
      - '2025-12-12T13:10:46.321Z'
      x-api-received:
      - '2025-12-12T13:10:46.310Z'
      x-inference-version:
      - v2
      x-ratelimit:
      - 'false'
      x-ratelimit-limit:
      - '10'
      x-ratelimit-limit-tokens:
      - '3000'
      x-ratelimit-remaining:
      - '19'
      x-ratelimit-remaining-tokens:
      - '3000'
      x-ratelimit-reset:
      - '2'
      x-request-id:
      - oNvArbw-zqrih-9acd76baed3ee37a
    status:
      code: 200
      message: OK
version: 1
