interactions:
- request:
    body: '{"contents": [{"parts": [{"text": "Who created you?"}], "role": "user"}]}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '73'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - google-genai-sdk/1.48.0 gl-python/3.10.15
      x-goog-api-client:
      - google-genai-sdk/1.48.0 gl-python/3.10.15
      x-goog-api-key:
      - <filtered>
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAC/2WQQU/CQBCF7/0Vmz0XIiiYeDNqCAcCkWo0xpjRDu2G7U7dnRoI4b+7bSks2sNm
        Mu/1zcy3i4SQX2BSlQKjkzfizXeE2DVvrZFhNOyFruWbJVg+edtvF9Tewripf5JTAYUAocFm6F+T
        VeCLglLUsWALymAqPrdiQpRp7MsgZX+s3+PTbEsa6+AmorPvO4NcKaNc/ojgyNS2ZTJfyKOqTIob
        376IugFNtKyc32qGDJ4CHG+VpaWi5ITWaO6oaiiM2qyA2Zk8GBx0JgZ9Lo0v43+x7t4PVTqEGXD2
        N4JWvK0PSR5eEhlw4LOtOg5RgEtyTlWW858Nr66jA7CW4TNap1pYGRYeX2/YH/VWGlzezJMWXUnG
        4TStPU+TbAav4+W8+iiHlhb655vXt05G++gXslCsBU0CAAA=
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Thu, 06 Nov 2025 09:20:18 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=1613
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens":16000,"messages":[{"role":"user","content":"Who created you?"},{"role":"assistant","content":"I
      am a large language model, trained by Google."},{"role":"user","content":"Can
      you double-check that?"}],"anthropic_version":"bedrock-2023-05-31"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      authorization:
      - <filtered>
      connection:
      - keep-alive
      content-length:
      - '255'
      content-type:
      - application/json
      host:
      - bedrock-runtime.us-east-1.amazonaws.com
      user-agent:
      - AnthropicBedrock/Python 0.72.0
      x-amz-date:
      - <filtered>
      x-stainless-arch:
      - arm64
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 0.72.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.10.15
      x-stainless-timeout:
      - '600'
    method: POST
    uri: https://bedrock-runtime.us-east-1.amazonaws.com/model/us.anthropic.claude-haiku-4-5-20251001-v1:0/invoke
  response:
    body:
      string: '{"model":"claude-haiku-4-5-20251001","id":"msg_bdrk_01XkWs3BDQnwaPoEEjp6tC55","type":"message","role":"assistant","content":[{"type":"text","text":"You''re
        right to ask me to double-check. I apologize for the error. I''m Claude, and
        I was created by Anthropic, not Google. Thank you for catching that mistake."}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":35,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":44}}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '464'
      Content-Type:
      - application/json
      Date:
      - Thu, 06 Nov 2025 09:20:20 GMT
      X-Amzn-Bedrock-Input-Token-Count:
      - '35'
      X-Amzn-Bedrock-Invocation-Latency:
      - '1252'
      X-Amzn-Bedrock-Output-Token-Count:
      - '44'
      x-amzn-RequestId:
      - 88cbd80f-b22a-4bd7-9c7e-2fd0817116e9
    status:
      code: 200
      message: OK
version: 1
