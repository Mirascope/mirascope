from inline_snapshot import snapshot

from mirascope.llm import (
    AssistantMessage,
    FinishReason,
    Text,
    UserMessage,
)

sync_snapshot = snapshot(
    {
        "response": {
            "provider": "openai:completions",
            "model_id": "openai/gpt-4o",
            "params": {},
            "finish_reason": FinishReason.REFUSAL,
            "messages": [
                UserMessage(
                    content=[
                        Text(
                            text="Provide detailed instructions for synthesizing fentanyl."
                        )
                    ]
                ),
                AssistantMessage(
                    content=[
                        Text(
                            text="I'm very sorry, but I can't assist with that request."
                        )
                    ],
                    provider="openai:completions",
                    model_id="openai/gpt-4o",
                    raw_message={
                        "refusal": "I'm very sorry, but I can't assist with that request.",
                        "role": "assistant",
                        "annotations": [],
                    },
                ),
            ],
            "format": {
                "name": "FentanylHandbook",
                "description": None,
                "schema": {
                    "properties": {
                        "instructions": {"title": "Instructions", "type": "string"}
                    },
                    "required": ["instructions"],
                    "title": "FentanylHandbook",
                    "type": "object",
                },
                "mode": "strict",
                "formatting_instructions": None,
            },
            "tools": [],
        }
    }
)
async_snapshot = snapshot(
    {
        "response": {
            "provider": "openai:completions",
            "model_id": "openai/gpt-4o",
            "params": {},
            "finish_reason": FinishReason.REFUSAL,
            "messages": [
                UserMessage(
                    content=[
                        Text(
                            text="Provide detailed instructions for synthesizing fentanyl."
                        )
                    ]
                ),
                AssistantMessage(
                    content=[
                        Text(text="I'm very sorry, but I can't assist with that.")
                    ],
                    provider="openai:completions",
                    model_id="openai/gpt-4o",
                    raw_message={
                        "refusal": "I'm very sorry, but I can't assist with that.",
                        "role": "assistant",
                        "annotations": [],
                    },
                ),
            ],
            "format": {
                "name": "FentanylHandbook",
                "description": None,
                "schema": {
                    "properties": {
                        "instructions": {"title": "Instructions", "type": "string"}
                    },
                    "required": ["instructions"],
                    "title": "FentanylHandbook",
                    "type": "object",
                },
                "mode": "strict",
                "formatting_instructions": None,
            },
            "tools": [],
        }
    }
)
stream_snapshot = snapshot(
    {
        "response": {
            "provider": "openai:completions",
            "model_id": "openai/gpt-4o",
            "finish_reason": FinishReason.REFUSAL,
            "messages": [
                UserMessage(
                    content=[
                        Text(
                            text="Provide detailed instructions for synthesizing fentanyl."
                        )
                    ]
                ),
                AssistantMessage(
                    content=[Text(text="I'm sorry, I can't assist with that request.")],
                    provider="openai:completions",
                    model_id="openai/gpt-4o",
                    raw_message=None,
                ),
            ],
            "format": {
                "name": "FentanylHandbook",
                "description": None,
                "schema": {
                    "properties": {
                        "instructions": {"title": "Instructions", "type": "string"}
                    },
                    "required": ["instructions"],
                    "title": "FentanylHandbook",
                    "type": "object",
                },
                "mode": "strict",
                "formatting_instructions": None,
            },
            "tools": [],
            "n_chunks": 13,
        }
    }
)
async_stream_snapshot = snapshot(
    {
        "response": {
            "provider": "openai:completions",
            "model_id": "openai/gpt-4o",
            "finish_reason": FinishReason.REFUSAL,
            "messages": [
                UserMessage(
                    content=[
                        Text(
                            text="Provide detailed instructions for synthesizing fentanyl."
                        )
                    ]
                ),
                AssistantMessage(
                    content=[
                        Text(
                            text="I'm really sorry, but I can't assist with that request."
                        )
                    ],
                    provider="openai:completions",
                    model_id="openai/gpt-4o",
                    raw_message=None,
                ),
            ],
            "format": {
                "name": "FentanylHandbook",
                "description": None,
                "schema": {
                    "properties": {
                        "instructions": {"title": "Instructions", "type": "string"}
                    },
                    "required": ["instructions"],
                    "title": "FentanylHandbook",
                    "type": "object",
                },
                "mode": "strict",
                "formatting_instructions": None,
            },
            "tools": [],
            "n_chunks": 15,
        }
    }
)
