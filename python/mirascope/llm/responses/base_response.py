"""Base interface for LLM responses."""

from collections.abc import Sequence
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Generic

from ..content import AssistantContent, Text, Thinking, ToolCall
from ..formatting import FormatT
from ..messages import Message
from .finish_reason import FinishReason
from .usage import Usage

if TYPE_CHECKING:
    from ..clients import (
        REGISTERED_LLMS,
    )


@dataclass
class BaseResponse(Generic[FormatT]):
    """Base class for LLM responses."""

    model: REGISTERED_LLMS
    """The model identifier that generated the response (e.g. "openai:gpt-4", "anthropic:claude-3-5-sonnet-latest")."""

    args: dict[str, Any]
    """The arguments used to generate the response."""

    messages: list[Message]
    """The message history, including the most recent assistant message."""

    template: str | None
    """The string template used to define the messages array, if any."""

    raw: Any
    """The raw response from the LLM."""

    content: Sequence[AssistantContent]
    """The content generated by the LLM."""

    texts: Sequence[Text]
    """The text content in the generated response, if any."""

    tool_calls: Sequence[ToolCall]
    """The tools the LLM wants called on its behalf, if any."""

    thinkings: Sequence[Thinking]
    """The thinking content in the generated response, if any."""

    finish_reason: FinishReason | None
    """The reason why the LLM finished generating a response."""

    usage: Usage | None
    """The token usage statistics for this response, if available."""

    @property
    def text(self) -> Text | None:
        """Returns the response's textual content, if present.

        If the response has multiple Text parts, they will be concatenated together into
        a single Text part.
        """
        raise NotImplementedError()

    def format(self) -> FormatT:
        """Format the response according to the response format parser.

        It will parse the response content according to the specified format (if present)
        and return a structured object.

        Returns:
            The formatted response object of type FormatT.

        Raises:
            ValueError: If the response cannot be formatted according to the
                specified format.
        """
        raise NotImplementedError()

    def __repr__(self) -> str:
        """Return a string representation of all response content including embedded media.

        The resulting string includes all raw text directly, and includes placeholder
        representations for embedded media, eg {image: url=...} or {thinking: thoughts=...}

        Each content piece will be separated by newlines.
        """
        raise NotImplementedError()
