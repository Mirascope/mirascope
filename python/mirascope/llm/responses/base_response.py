"""The `BaseResponse` class for LLM responses."""

from collections.abc import Sequence
from dataclasses import dataclass
from decimal import Decimal
from typing import TYPE_CHECKING, Any, Generic

from typing_extensions import TypeVar

from ..content import Audio, Image, Thinking, Video
from ..messages import Message
from ..tools import ContextTool, Tool
from ..types import Jsonable
from .content import BaseResponseContent
from .finish_reason import FinishReason
from .usage import Usage

if TYPE_CHECKING:
    from ..clients import (
        REGISTERED_LLMS,
    )


ResponseContentT = TypeVar("ResponseContentT", bound=BaseResponseContent)
ToolT = TypeVar("ToolT", bound=Tool[..., Jsonable] | ContextTool[..., Jsonable, Any])
T = TypeVar("T", bound=object | None, default=None)


@dataclass
class BaseResponse(Generic[ResponseContentT, ToolT, T]):
    """The response generated by an LLM."""

    raw: Any
    """The raw response from the LLM."""

    model: REGISTERED_LLMS
    """The model identifier that generated the response (e.g. "openai:gpt-4", "anthropic:claude-3-5-sonnet-latet")."""

    args: dict[str, Any]
    """The arguments used to generate the response."""

    template: str | None
    """The string template used to define the messages array, if any."""

    messages: list[Message]
    """The messages used to generate the response."""

    content: Sequence[ResponseContentT]
    """The content generated by the LLM."""

    texts: Sequence[str]
    """The text content in the generated response, if any."""

    images: Sequence[Image]
    """The image content in the generated response, if any."""

    audios: Sequence[Audio]
    """The audio content in the generated response, if any."""

    videos: Sequence[Video]
    """The video content in the generated response, if any."""

    thinkings: Sequence[Thinking]
    """The thinking content in the generated response, if any."""

    finish_reason: FinishReason
    """The reason why the LLM finished generating a response."""

    usage: Usage | None
    """The token usage statistics for the request to the LLM."""

    cost: Decimal | None
    """The cost of the request to the LLM, if available."""

    tools: Sequence[ToolT]
    """The tools the LLM wants called on its behalf, if any."""

    @property
    def tool(self) -> ToolT | None:
        """Returns the first tool used in the response, if any."""
        raise NotImplementedError()

    @property
    def text(self) -> str | None:
        """Returns the first text in the response content, if any."""
        raise NotImplementedError()

    @property
    def image(self) -> Image | None:
        """Returns the first image in the response content, if any."""
        raise NotImplementedError()

    @property
    def audio(self) -> Audio | None:
        """Returns the first audio in the response content, if any."""
        raise NotImplementedError()

    @property
    def video(self) -> Video | None:
        """Returns the first video in the response content, if any."""
        raise NotImplementedError()

    @property
    def thinking(self) -> Thinking | None:
        """Returns the first thinking in the response content, if any."""
        raise NotImplementedError()

    def format(self) -> T:
        """Format the response according to the response format parser.

        This method is only available if the call was created with a T.
        It will parse the response content according to the specified format and return
        a structured object.

        Returns:
            The formatted response object of type T.

        Raises:
            ValueError: If the response cannot be formatted according to the
                specified format.
        """
        raise NotImplementedError()

    def __repr__(self) -> str:
        """Return a string representation of all response content including embedded media.

        The resulting string includes all raw text directly, and includes placeholder
        representations for embedded media, eg {image: url=...} or {thinking: thoughts=...}

        Each content piece will be separated by newlines.
        """
        raise NotImplementedError()
