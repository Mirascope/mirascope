"""Interfaces for LLM responses.

This module defines interfaces for the responses returned by language models,
including methods for formatting the response according to a specified format.
"""

from collections.abc import Iterator, Sequence
from dataclasses import dataclass
from enum import Enum
from typing import Any, Generic

from typing_extensions import TypeVar

from .messages import Audio, DynamicConfig, Image, ResponseContent, Text, Video
from .tools import Tool

T = TypeVar("T", default=None)


class FinishReason(str, Enum):
    """The reason why the LLM finished generating a response."""

    STOP = "stop"
    MAX_TOKENS = "max_tokens"


@dataclass
class Usage:
    """The usage statistics for a request to an LLM."""

    input_tokens: int
    """Number of tokens in the prompt (including messages, tools, etc)."""

    cached_tokens: int
    """Number of tokens used that were previously cached (and thus cheaper)."""

    output_tokens: int
    """Number of tokens in the generated output.
    
    TODO: figure out different types of output and how to handle that (e.g. audio)
    """

    total_tokens: int
    """Total number of tokens used in the request (prompt + completion)."""


@dataclass
class Response(Generic[T]):
    """The response generated by an LLM."""

    raw: Any
    """The raw response from the LLM."""

    provider: str
    """The provider of the LLM (e.g. "openai", "anthropic")."""

    model: str
    """The model used to generate the response (e.g. "gpt-4", "claude-3-5-sonnet-latet")."""

    args: dict[str, Any]
    """The arguments used to generate the response."""

    dynamic_config: DynamicConfig
    """The dynamic configuration used to generate the response."""

    template: str | None
    """The string template used to define the messages array, if any."""

    content: ResponseContent | Sequence[ResponseContent]
    """The content generated by the LLM."""

    texts: Sequence[Text] | None
    """The text content in the generated response, if any."""

    images: Sequence[Image] | None
    """The image content in the generated response, if any."""

    audios: Sequence[Audio] | None
    """The audio content in the generated response, if any."""

    videos: Sequence[Video] | None
    """The video content in the generated response, if any."""

    tools: Sequence[Tool] | None
    """The tools the LLM wants called on its behalf, if any."""

    finish_reason: FinishReason
    """The reason why the LLM finished generating a response."""

    usage: Usage | None
    """The usage statistics for the request to the LLM."""

    cost: float | None
    """The cost of the request to the LLM, if available."""

    @property
    def tool(self) -> Tool | None:
        """Returns the first tool used in the response, if any."""
        raise NotImplementedError()

    @property
    def text(self) -> str | None:
        """Returns the first text in the response content, if any."""
        raise NotImplementedError()

    @property
    def image(self) -> Image | None:
        """Returns the first image in the response content, if any."""
        raise NotImplementedError()

    @property
    def audio(self) -> Audio | None:
        """Returns the first audio in the response content, if any."""
        raise NotImplementedError()

    @property
    def video(self) -> Video | None:
        """Returns the first video in the response content, if any."""
        raise NotImplementedError()

    def __iter__(self) -> Iterator[ResponseContent]:
        """Iterate over the transformed response content.

        This method allows iteration over the response content, returning
        each item in the order they were generated. Each item will be transformed for
        convenience. For example, `Text` content will be extracted into simple `str`s,
        and `ToolCall` response content will be automatically converted into `Tool`
        instances for easy calling.

        Yields:
            The next item in the response content (text, image, audio, video, or tool).
        """
        raise NotImplementedError()

    def format(self) -> T:
        """Format the response according to the response format parser.

        This method is only available if the call was created with a ResponseFormat[T].
        It will parse the response content according to the specified format and return
        a structured object.

        Returns:
            The formatted response object of type T.

        Raises:
            ValueError: If the response cannot be formatted according to the
                specified format.
        """
        raise NotImplementedError()
