{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search Agent Implementation\n",
    "\n",
    "This notebook demonstrates the implementation of a Web Search Agent using the Mirascope library. The agent is capable of performing web searches and parsing webpage content to answer user queries.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setting Up the Environment](#setup)\n",
    "3. [Implementing the Tools](#tools)\n",
    "4. [Building the Web Search Agent](#building)\n",
    "5. [Running the Agent](#running)\n",
    "6. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The Web Search Agent is an AI-powered tool that combines the capabilities of Large Language Models (LLMs) with web search functionality. It can understand user queries, perform web searches, parse webpage content, and generate informative responses.\n",
    "\n",
    "Key components of our implementation include:\n",
    "- Mirascope library for LLM interactions\n",
    "- OpenAI's GPT model for natural language processing\n",
    "- Custom tools for web searching and webpage parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up the Environment <a name=\"setup\"></a>\n",
    "\n",
    "First, we need to install the required packages and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"mirascope[openai]\" requests beautifulsoup4 pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from openai.types.chat import ChatCompletionMessageParam\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from mirascope.core import openai, prompt_template\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing the Tools <a name=\"tools\"></a>\n",
    "\n",
    "Now, let's implement our tools: `web_search` and `parse_webpage`. These functions will allow our agent to search the web and extract content from webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Perform a web search and return the results.\n",
    "\n",
    "    This is a simplified implementation. In a real-world scenario,\n",
    "    you would integrate with a proper search engine API.\n",
    "    \"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"Search results for: {query}\"\n",
    "\n",
    "\n",
    "def parse_webpage(url: str) -> str:\n",
    "    \"\"\"Parse the content of a webpage.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        return \"\\n\".join([p.text for p in soup.find_all(\"p\")])\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing webpage: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the Web Search Agent <a name=\"building\"></a>\n",
    "\n",
    "Now that we have our tools ready, let's build the WebSearchAgent class. This class will use the Mirascope framework to create an AI agent that can interact with users, perform web searches, and provide informative responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RESULTS = 10\n",
    "\n",
    "\n",
    "class WebSearchAgent(BaseModel):\n",
    "    history: list[ChatCompletionMessageParam] = []\n",
    "    max_results: int = MAX_RESULTS\n",
    "\n",
    "    @openai.call(\"gpt-4o-mini\", stream=True, tools=[parse_webpage, web_search])\n",
    "    @prompt_template(\"\"\"\n",
    "        SYSTEM:\n",
    "        Your task is to answer a user's query.\n",
    "\n",
    "        You have access to the following tools:\n",
    "        - `web_search`: Search the web for information (limited to {self.max_results} results).\n",
    "        - `parse_webpage`: Parse the content of a webpage.\n",
    "\n",
    "        When calling the `web_search` tool, the `body` is simply the body of the search\n",
    "        result. You MUST then call the `parse_webpage` tool to get the actual content\n",
    "        of the webpage. It is up to you to determine which search results to parse.\n",
    "\n",
    "        Once you have gathered all of the information you need, generate your response,\n",
    "        which should strike the right balance between brevity and completeness. You answer\n",
    "        to the user's query should be concise yet comprehensive.\n",
    "\n",
    "        MESSAGES: {self.history}\n",
    "        USER: {query}\n",
    "        \"\"\")\n",
    "    def _stream(self, query: str): ...\n",
    "\n",
    "    def _step(self, query: str):\n",
    "        stream = self._stream(query)\n",
    "        tools_and_outputs = []\n",
    "        for chunk, tool in stream:\n",
    "            if tool:\n",
    "                tools_and_outputs.append((tool, tool.call()))\n",
    "            else:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        if stream.user_message_param:\n",
    "            self.history.append(stream.user_message_param)\n",
    "        self.history.append(stream.message_param)\n",
    "        if tools_and_outputs:\n",
    "            self.history += stream.tool_message_params(tools_and_outputs)\n",
    "            self._step(\"\")\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            query = input(\"(User): \")\n",
    "            if query.lower() in [\"exit\", \"quit\"]:\n",
    "                break\n",
    "            print(\"(Assistant): \", end=\"\", flush=True)\n",
    "            self._step(query)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the key components of our WebSearchAgent class:\n",
    "\n",
    "1. **@openai.call decorator**: This decorator configures the LLM call using OpenAI's model. It specifies the use of the \"gpt-4o-mini\" model, enables streaming, and provides access to the `parse_webpage` and `web_search` tools.\n",
    "\n",
    "2. **@prompt_template decorator**: This decorator defines the prompt template sent to the LLM. It allows for dynamic insertion of variables like `{self.max_results}` and `{self.history}`.\n",
    "\n",
    "3. **_stream method**: This method generates streaming responses using the OpenAI model. The actual implementation is provided by the Mirascope library, so we don't need to implement the function body.\n",
    "\n",
    "4. **_step method**: This method processes a single user query. It handles the streaming response, tool calls, and updates the conversation history.\n",
    "\n",
    "5. **run method**: This method provides a simple command-line interface for interacting with the agent. It continuously prompts for user input until the user chooses to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running the Agent <a name=\"running\"></a>\n",
    "\n",
    "Now that we have implemented our WebSearchAgent, let's create an instance and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = WebSearchAgent()\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now interact with your Web Search Agent! Try asking it questions that require web searches, like \"What are the latest developments in artificial intelligence?\" or \"Can you summarize the plot of the latest popular movie?\"\n",
    "\n",
    "Remember, to exit the agent, simply type \"exit\" or \"quit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion <a name=\"conclusion\"></a>\n",
    "\n",
    "You've successfully implemented a Web Search Agent using the Mirascope library. This agent demonstrates the power of combining LLMs with custom tools for web searching and content parsing.\n",
    "\n",
    "Key takeaways:\n",
    "1. Custom tools like `web_search` and `parse_webpage` extend the agent's functionality.\n",
    "2. The `@openai.call` and `@prompt_template` decorators streamline the configuration of LLM interactions.\n",
    "3. Streaming responses allow for real-time interaction with the agent.\n",
    "\n",
    "This implementation serves as a starting point. You can further enhance the agent by:\n",
    "- Implementing a more sophisticated web search function\n",
    "- Adding error handling and retries for web requests\n",
    "- Extending the agent's capabilities with additional tools\n",
    "- Optimizing the prompt template for better responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
