{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search Agent Implementation\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setting Up the Environment](#setup)\n",
    "3. [Implementing the Tools](#tools)\n",
    "4. [Building the Web Search Agent](#building)\n",
    "5. [Running the Agent](#running)\n",
    "6. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The Web Search Agent is an AI-powered tool that combines the capabilities of Large Language Models (LLMs) with web search functionality. It can understand user queries, perform web searches, parse webpage content, and generate informative responses.\n",
    "\n",
    "Key components of our implementation include:\n",
    "- [Mirascope](https://www.mirascope.io/) library for LLM interactions\n",
    "- [OpenAI](https://openai.com/)'s GPT model for natural language processing\n",
    "- Custom tools for web searching and webpage parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": "## 2. Setting Up the Environment <a name=\"setup\"></a>\n\nFirst, we need to install the required packages and import the necessary modules."
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "!pip install \"mirascope[openai]\" requests beautifulsoup4 pydantic duckduckgo-search"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from mirascope.core import BaseMessageParam, openai, prompt_template"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Implementing the Tools <a name=\"tools\"></a>\n\nNow, let's implement our tools: `web_search` and `parse_webpage`. These functions will allow our agent to search the web and extract content from webpages."
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "MAX_RESULTS = 10\n",
    "\n",
    "\n",
    "def web_search(text: str) -> str:\n",
    "    \"\"\"Search the web for the given text.\n",
    "\n",
    "    Args:\n",
    "        text: The text to search for.\n",
    "\n",
    "    Returns:\n",
    "        The search results for the given text, containing the `title`, `href`, and `body`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = DDGS(proxy=None).text(text, max_results=MAX_RESULTS)\n",
    "        return \"\\n\\n\".join(\n",
    "            [\n",
    "                \"title: {title}\\nhref: {href}\\nbody: {body}\".format(**result)\n",
    "                for result in results\n",
    "            ]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"{type(e)}: Failed to search the web for text\"\n",
    "\n",
    "\n",
    "def parse_webpage(link: str) -> str:\n",
    "    \"\"\"Parse the paragraphs of the webpage found at `link`.\n",
    "\n",
    "    Args:\n",
    "        link: The URL of the webpage.\n",
    "\n",
    "    Returns:\n",
    "        The parsed paragraphs of the webpage, separated by newlines.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        return \"\\n\".join([p.text for p in soup.find_all(\"p\")])\n",
    "    except Exception as e:\n",
    "        return f\"{type(e)}: Failed to parse content from URL\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Building the Web Search Agent <a name=\"building\"></a>\n\nNow that we have our tools ready, let's build the WebSearchAgent class. This class will use the Mirascope framework to create an AI agent that can interact with users, perform web searches, and provide informative responses."
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "class WebSearchAgent(BaseModel):\n",
    "    history: list[BaseMessageParam | openai.OpenAIMessageParam] = []\n",
    "\n",
    "    @openai.call(\"gpt-4o-mini\", stream=True, tools=[web_search, parse_webpage])\n",
    "    @prompt_template(\"\"\"\n",
    "        SYSTEM:\n",
    "        Your task is to answer a user's query. The current date is {current_date}.\n",
    "\n",
    "        You have access to the following tools:\n",
    "        - `web_search`: Search the web for information.\n",
    "        - `parse_webpage`: Parse the content of a webpage.\n",
    "\n",
    "        When calling the `web_search` tool, the `body` is simply the body of the search\n",
    "        result. You MUST then call the `parse_webpage` tool to get the actual content\n",
    "        of the webpage. It is up to you to determine which search results to parse.\n",
    "\n",
    "        Once you have gathered all of the information you need, generate your response,\n",
    "        which should strike the right balance between brevity and completeness. Your answer\n",
    "        to the user's query should be concise yet comprehensive. When discussing recent\n",
    "        events or developments, make sure to consider the current date provided.\n",
    "\n",
    "        MESSAGES: {self.history}\n",
    "        USER: {query}\n",
    "        \"\"\")\n",
    "    def _stream(self, query: str):\n",
    "        return {\n",
    "            \"computed_fields\": {\"current_date\": datetime.now().strftime(\"%Y-%m-%d\")}\n",
    "        }\n",
    "\n",
    "    def _step(self, query: str):\n",
    "        stream = self._stream(query)\n",
    "        tools_and_outputs = []\n",
    "        for chunk, tool in stream:\n",
    "            if tool:\n",
    "                tools_and_outputs.append((tool, tool.call()))\n",
    "            else:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        if stream.user_message_param:\n",
    "            self.history.append(stream.user_message_param)\n",
    "        self.history.append(stream.message_param)\n",
    "        if tools_and_outputs:\n",
    "            self.history += stream.tool_message_params(tools_and_outputs)\n",
    "            self._step(\"\")\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            query = input(\"(User): \")\n",
    "            if query.lower() in [\"exit\", \"quit\"]:\n",
    "                break\n",
    "            print(\"(Assistant): \", end=\"\", flush=True)\n",
    "            self._step(query)\n",
    "            print(\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the key components of our WebSearchAgent class:\n",
    "\n",
    "1. **@openai.call decorator**: This decorator configures the LLM call using OpenAI's model. It specifies the use of the \"gpt-4o-mini\" model, enables streaming, and provides access to the `parse_webpage` and `web_search` tools.\n",
    "\n",
    "2. **@prompt_template decorator**: This decorator defines the prompt template sent to the LLM. It allows for dynamic insertion of variables like `{current_date}` and `{self.history}`.\n",
    "\n",
    "3. **_stream method**: This method generates streaming responses using the OpenAI model. The actual implementation is provided by the Mirascope library, so we don't need to implement the function body.\n",
    "\n",
    "4. **_step method**: This method processes a single user query. It handles the streaming response, tool calls, and updates the conversation history.\n",
    "\n",
    "5. **run method**: This method provides a simple command-line interface for interacting with the agent. It continuously prompts for user input until the user chooses to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running the Agent <a name=\"running\"></a>\n",
    "\n",
    "Now that we have implemented our WebSearchAgent, let's create an instance and run it. Here's an example of how the agent responds to a query about upcoming Python releases:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "agent = WebSearchAgent()\n",
    "agent.run()\n",
    "\n",
    "# > (User): What is the next Python release version?\n",
    "# > (Assistant): The next Python release will be **Python 3.13**, expected to be officially released on **October 1, 2024**. This version is currently in prerelease status. After this, Python 3.14 is scheduled for release on **October 1, 2025**, marking the beginning of a new feature branch.\n",
    "\n",
    "# Python 3.13 is important as it will introduce new features and enhancements, while Python 3.14 is anticipated to follow in the established release cadence outlined in PEP 602, which involves a 17-month development period and periodic updates thereafter."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now interact with your Web Search Agent! Try asking it questions that require web searches, like \"What are the latest developments in artificial intelligence?\" or \"Can you summarize the plot of the latest popular movie?\"\n",
    "\n",
    "Remember, to exit the agent, simply type \"exit\" or \"quit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Conclusion <a name=\"conclusion\"></a>\n\nYou've successfully implemented a Web Search Agent using the Mirascope library. This agent demonstrates the power of combining LLMs with custom tools for web searching and content parsing.\n\nKey takeaways:\n1. Custom tools like `web_search` and `parse_webpage` extend the agent's functionality.\n2. The `@openai.call` and `@prompt_template` decorators streamline the configuration of LLM interactions.\n3. Streaming responses allow for real-time interaction with the agent.\n\nThis implementation serves as a starting point. You can further enhance the agent by:\n- Implementing a more sophisticated web search function\n- Adding error handling and retries for web requests\n- Extending the agent's capabilities with additional tools\n- Optimizing the prompt template for better responses\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
