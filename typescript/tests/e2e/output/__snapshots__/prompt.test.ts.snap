// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`prompt output > [anthropic] calls model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "4200 + 42 = 4242",
            "type": "text",
          },
        ],
        "modelId": "anthropic/claude-haiku-4-5",
        "name": null,
        "providerId": "anthropic",
        "providerModelName": "claude-haiku-4-5",
        "rawMessage": {
          "content": [
            {
              "text": "4200 + 42 = 4242",
              "type": "text",
            },
          ],
          "role": "assistant",
        },
        "role": "assistant",
      },
    ],
    "modelId": "anthropic/claude-haiku-4-5",
    "providerId": "anthropic",
    "providerModelName": "claude-haiku-4-5",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 17,
      "outputTokens": 15,
      "raw": "[object Object]",
      "reasoningTokens": 0,
      "totalTokens": 32,
    },
  },
}
`;

exports[`prompt output > [anthropic] streams model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "4200 + 42 = 4242",
            "type": "text",
          },
        ],
        "modelId": "anthropic/claude-haiku-4-5",
        "name": null,
        "providerId": "anthropic",
        "providerModelName": "claude-haiku-4-5",
        "rawMessage": null,
        "role": "assistant",
      },
    ],
    "modelId": "anthropic/claude-haiku-4-5",
    "nChunks": 4,
    "providerId": "anthropic",
    "providerModelName": "claude-haiku-4-5",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 17,
      "outputTokens": 16,
      "raw": "null",
      "reasoningTokens": 0,
      "totalTokens": 33,
    },
  },
}
`;

exports[`prompt output > [google] calls model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "4200 + 42 = **4242**",
            "type": "text",
          },
        ],
        "modelId": "google/gemini-2.5-flash",
        "name": null,
        "providerId": "google",
        "providerModelName": "gemini-2.5-flash",
        "rawMessage": {
          "parts": [
            {
              "text": "4200 + 42 = **4242**",
            },
          ],
          "role": "model",
        },
        "role": "assistant",
      },
    ],
    "modelId": "google/gemini-2.5-flash",
    "providerId": "google",
    "providerModelName": "gemini-2.5-flash",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 13,
      "outputTokens": 79,
      "raw": "[object Object]",
      "reasoningTokens": 64,
      "totalTokens": 92,
    },
  },
}
`;

exports[`prompt output > [google] streams model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "To find the sum of 4200 and 42, you simply add the numbers:

4200
+ 42
-----
4242

So, 4200 + 42 = **4242**.",
            "type": "text",
          },
        ],
        "modelId": "google/gemini-2.5-flash",
        "name": null,
        "providerId": "google",
        "providerModelName": "gemini-2.5-flash",
        "rawMessage": GenerateContentResponse {
          "candidates": [
            {
              "content": {
                "parts": [
                  {
                    "text": "2

So, 4200 + 42 = **4242**.",
                  },
                ],
                "role": "model",
              },
              "finishReason": "STOP",
              "index": 0,
            },
          ],
          "modelVersion": "gemini-2.5-flash",
          "responseId": "B7N5adXeGvm7qtsP3_zSsAU",
          "sdkHttpResponse": {
            "headers": {
              "alt-svc": "h3=":443"; ma=2592000,h3-29=":443"; ma=2592000",
              "content-disposition": "attachment",
              "content-type": "text/event-stream",
              "date": "Wed, 28 Jan 2026 06:56:08 GMT",
              "server": "scaffolding on HTTPServer2",
              "server-timing": "gfet4t7; dur=1102",
              "transfer-encoding": "chunked",
              "vary": "Origin, X-Origin, Referer",
              "x-content-type-options": "nosniff",
              "x-frame-options": "SAMEORIGIN",
              "x-xss-protection": "0",
            },
          },
          "usageMetadata": {
            "candidatesTokenCount": 57,
            "promptTokenCount": 13,
            "promptTokensDetails": [
              {
                "modality": "TEXT",
                "tokenCount": 13,
              },
            ],
            "thoughtsTokenCount": 78,
            "totalTokenCount": 148,
          },
        },
        "role": "assistant",
      },
    ],
    "modelId": "google/gemini-2.5-flash",
    "nChunks": 4,
    "providerId": "google",
    "providerModelName": "gemini-2.5-flash",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 26,
      "outputTokens": 250,
      "raw": "null",
      "reasoningTokens": 156,
      "totalTokens": 276,
    },
  },
}
`;

exports[`prompt output > [openai:completions] calls model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "4242",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:completions",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:completions",
        "rawMessage": {
          "annotations": [],
          "content": "4242",
          "role": "assistant",
        },
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:completions",
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:completions",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 15,
      "outputTokens": 11,
      "raw": "[object Object]",
      "reasoningTokens": 0,
      "totalTokens": 26,
    },
  },
}
`;

exports[`prompt output > [openai:completions] streams model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "4242",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:completions",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:completions",
        "rawMessage": {
          "choices": [],
          "created": 1769583369,
          "id": "chatcmpl-D2tlBDytyu2mAQLsu4el7LJ77ZyqU",
          "model": "gpt-5-mini-2025-08-07",
          "obfuscation": "Fktljw",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": null,
          "usage": {
            "completion_tokens": 11,
            "completion_tokens_details": {
              "accepted_prediction_tokens": 0,
              "audio_tokens": 0,
              "reasoning_tokens": 0,
              "rejected_prediction_tokens": 0,
            },
            "prompt_tokens": 15,
            "prompt_tokens_details": {
              "audio_tokens": 0,
              "cached_tokens": 0,
            },
            "total_tokens": 26,
          },
        },
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:completions",
    "nChunks": 5,
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:completions",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 15,
      "outputTokens": 11,
      "raw": "null",
      "reasoningTokens": 0,
      "totalTokens": 26,
    },
  },
}
`;

exports[`prompt output > [openai:responses] calls model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "4242",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:responses",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:responses",
        "rawMessage": [
          {
            "id": "rs_0855f1598ff53e8f006976feaedec481a0a76a5f964eabe8b5",
            "summary": [],
            "type": "reasoning",
          },
          {
            "content": [
              {
                "annotations": [],
                "logprobs": [],
                "text": "4242",
                "type": "output_text",
              },
            ],
            "id": "msg_0855f1598ff53e8f006976feafbb0881a0a22c1eefea657031",
            "role": "assistant",
            "status": "completed",
            "type": "message",
          },
        ],
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:responses",
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:responses",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 15,
      "outputTokens": 72,
      "raw": "[object Object]",
      "reasoningTokens": 64,
      "totalTokens": 87,
    },
  },
}
`;

exports[`prompt output > [openai:responses] streams model with string model id 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 4200 + 42?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "4242",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:responses",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:responses",
        "rawMessage": {
          "background": false,
          "completed_at": null,
          "created_at": 1769583370,
          "error": null,
          "frequency_penalty": 0,
          "id": "resp_024a09d27ce66b30006979b30a1be881a39cd19db19e35da22",
          "incomplete_details": null,
          "instructions": null,
          "max_output_tokens": null,
          "max_tool_calls": null,
          "metadata": {},
          "model": "gpt-5-mini-2025-08-07",
          "object": "response",
          "output": [],
          "parallel_tool_calls": true,
          "presence_penalty": 0,
          "previous_response_id": null,
          "prompt_cache_key": null,
          "prompt_cache_retention": null,
          "reasoning": {
            "effort": "medium",
            "summary": null,
          },
          "safety_identifier": null,
          "service_tier": "auto",
          "status": "in_progress",
          "store": true,
          "temperature": 1,
          "text": {
            "format": {
              "type": "text",
            },
            "verbosity": "medium",
          },
          "tool_choice": "auto",
          "tools": [],
          "top_logprobs": 0,
          "top_p": 1,
          "truncation": "disabled",
          "usage": null,
          "user": null,
        },
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:responses",
    "nChunks": 4,
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:responses",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 15,
      "outputTokens": 37,
      "raw": "null",
      "reasoningTokens": 0,
      "totalTokens": 52,
    },
  },
}
`;
