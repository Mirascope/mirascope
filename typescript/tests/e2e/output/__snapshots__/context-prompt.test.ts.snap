// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`context prompt output > [anthropic] calls model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "42 * 10 = 420",
            "type": "text",
          },
        ],
        "modelId": "anthropic/claude-haiku-4-5",
        "name": null,
        "providerId": "anthropic",
        "providerModelName": "claude-haiku-4-5",
        "rawMessage": {
          "content": [
            {
              "text": "42 * 10 = 420",
              "type": "text",
            },
          ],
          "role": "assistant",
        },
        "role": "assistant",
      },
    ],
    "modelId": "anthropic/claude-haiku-4-5",
    "providerId": "anthropic",
    "providerModelName": "claude-haiku-4-5",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 16,
      "outputTokens": 13,
      "raw": "[object Object]",
      "reasoningTokens": 0,
      "totalTokens": 29,
    },
  },
}
`;

exports[`context prompt output > [anthropic] streams model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "42 * 10 = 420",
            "type": "text",
          },
        ],
        "modelId": "anthropic/claude-haiku-4-5",
        "name": null,
        "providerId": "anthropic",
        "providerModelName": "claude-haiku-4-5",
        "rawMessage": {
          "content": [
            {
              "text": "42 * 10 = 420",
              "type": "text",
            },
          ],
          "role": "assistant",
        },
        "role": "assistant",
      },
    ],
    "modelId": "anthropic/claude-haiku-4-5",
    "nChunks": 4,
    "providerId": "anthropic",
    "providerModelName": "claude-haiku-4-5",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 16,
      "outputTokens": 21,
      "raw": "null",
      "reasoningTokens": 0,
      "totalTokens": 37,
    },
  },
}
`;

exports[`context prompt output > [google] calls model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "42 * 10 = 420",
            "type": "text",
          },
        ],
        "modelId": "google/gemini-2.5-flash",
        "name": null,
        "providerId": "google",
        "providerModelName": "gemini-2.5-flash",
        "rawMessage": {
          "parts": [
            {
              "text": "42 * 10 = 420",
            },
          ],
          "role": "model",
        },
        "role": "assistant",
      },
    ],
    "modelId": "google/gemini-2.5-flash",
    "providerId": "google",
    "providerModelName": "gemini-2.5-flash",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 11,
      "outputTokens": 64,
      "raw": "[object Object]",
      "reasoningTokens": 53,
      "totalTokens": 75,
    },
  },
}
`;

exports[`context prompt output > [google] streams model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "42 * 10 = 420",
            "type": "text",
          },
        ],
        "modelId": "google/gemini-2.5-flash",
        "name": null,
        "providerId": "google",
        "providerModelName": "gemini-2.5-flash",
        "rawMessage": {
          "parts": [
            {
              "text": "42",
            },
            {
              "text": " * 10 = 420",
            },
          ],
          "role": "model",
        },
        "role": "assistant",
      },
    ],
    "modelId": "google/gemini-2.5-flash",
    "nChunks": 4,
    "providerId": "google",
    "providerModelName": "gemini-2.5-flash",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 22,
      "outputTokens": 41,
      "raw": "null",
      "reasoningTokens": 28,
      "totalTokens": 63,
    },
  },
}
`;

exports[`context prompt output > [openai:completions] calls model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "420",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:completions",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:completions",
        "rawMessage": {
          "annotations": [],
          "content": "420",
          "role": "assistant",
        },
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:completions",
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:completions",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 14,
      "outputTokens": 10,
      "raw": "[object Object]",
      "reasoningTokens": 0,
      "totalTokens": 24,
    },
  },
}
`;

exports[`context prompt output > [openai:completions] streams model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "420",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:completions",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:completions",
        "rawMessage": {
          "choices": [],
          "created": 1769585518,
          "id": "chatcmpl-D2uJqxLS71HHTTZ8iImR2EbUMNJVE",
          "model": "gpt-5-mini-2025-08-07",
          "obfuscation": "WGGIQK",
          "object": "chat.completion.chunk",
          "service_tier": "default",
          "system_fingerprint": null,
          "usage": {
            "completion_tokens": 10,
            "completion_tokens_details": {
              "accepted_prediction_tokens": 0,
              "audio_tokens": 0,
              "reasoning_tokens": 0,
              "rejected_prediction_tokens": 0,
            },
            "prompt_tokens": 14,
            "prompt_tokens_details": {
              "audio_tokens": 0,
              "cached_tokens": 0,
            },
            "total_tokens": 24,
          },
        },
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:completions",
    "nChunks": 4,
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:completions",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 14,
      "outputTokens": 10,
      "raw": "null",
      "reasoningTokens": 0,
      "totalTokens": 24,
    },
  },
}
`;

exports[`context prompt output > [openai:responses] calls model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "420",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:responses",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:responses",
        "rawMessage": [
          {
            "id": "rs_09869a3f40b7ef33006979bb6b718c8195b11793329900c657",
            "summary": [],
            "type": "reasoning",
          },
          {
            "content": [
              {
                "annotations": [],
                "logprobs": [],
                "text": "420",
                "type": "output_text",
              },
            ],
            "id": "msg_09869a3f40b7ef33006979bb6bfcd881958d0706904c3025dd",
            "role": "assistant",
            "status": "completed",
            "type": "message",
          },
        ],
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:responses",
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:responses",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 14,
      "outputTokens": 52,
      "raw": "[object Object]",
      "reasoningTokens": 0,
      "totalTokens": 66,
    },
  },
}
`;

exports[`context prompt output > [openai:responses] streams model with context 1`] = `
{
  "response": {
    "finishReason": null,
    "format": null,
    "messages": [
      {
        "content": [
          {
            "text": "What is 42 * 10?",
            "type": "text",
          },
        ],
        "name": null,
        "role": "user",
      },
      {
        "content": [
          {
            "text": "420",
            "type": "text",
          },
        ],
        "modelId": "openai/gpt-5-mini:responses",
        "name": null,
        "providerId": "openai",
        "providerModelName": "gpt-5-mini:responses",
        "rawMessage": {
          "background": false,
          "completed_at": null,
          "created_at": 1769585519,
          "error": null,
          "frequency_penalty": 0,
          "id": "resp_0bea72c6ed62ec54006979bb6f2be48196b0f3f0114be8bbd8",
          "incomplete_details": null,
          "instructions": null,
          "max_output_tokens": null,
          "max_tool_calls": null,
          "metadata": {},
          "model": "gpt-5-mini-2025-08-07",
          "object": "response",
          "output": [],
          "parallel_tool_calls": true,
          "presence_penalty": 0,
          "previous_response_id": null,
          "prompt_cache_key": null,
          "prompt_cache_retention": null,
          "reasoning": {
            "effort": "medium",
            "summary": null,
          },
          "safety_identifier": null,
          "service_tier": "auto",
          "status": "in_progress",
          "store": true,
          "temperature": 1,
          "text": {
            "format": {
              "type": "text",
            },
            "verbosity": "medium",
          },
          "tool_choice": "auto",
          "tools": [],
          "top_logprobs": 0,
          "top_p": 1,
          "truncation": "disabled",
          "usage": null,
          "user": null,
        },
        "role": "assistant",
      },
    ],
    "modelId": "openai/gpt-5-mini:responses",
    "nChunks": 3,
    "providerId": "openai",
    "providerModelName": "gpt-5-mini:responses",
    "tools": [],
    "usage": {
      "cacheReadTokens": 0,
      "cacheWriteTokens": 0,
      "inputTokens": 14,
      "outputTokens": 46,
      "raw": "null",
      "reasoningTokens": 0,
      "totalTokens": 60,
    },
  },
}
`;
