/**
 * ContextResponse class for context-based LLM calls.
 *
 * Extends BaseResponse with context-aware functionality including:
 * - executeTools(): Execute tool calls with context dependency injection
 * - resume(): Continue the conversation with additional user content
 */

import type { Context } from '@/llm/context';
import type { UserContent } from '@/llm/messages';
import {
  BaseResponse,
  type BaseResponseInit,
} from '@/llm/responses/base-response';
import type { ContextStreamResponse } from '@/llm/responses/context-stream-response';

/**
 * Initialization options for creating a ContextResponse.
 */
export type ContextResponseInit = BaseResponseInit;

/**
 * The response generated by an LLM from a context call.
 *
 * This class provides context-aware functionality on top of the standard response:
 * - `executeTools()`: Execute all tool calls with context dependency injection
 * - `resume()`: Continue the conversation with additional user content
 *
 * @template DepsT - The type of dependencies in the context.
 *
 * @example
 * ```typescript
 * interface MyDeps { userId: string; }
 *
 * const ctx = createContext<MyDeps>({ userId: '123' });
 * const response = await myPrompt(model, ctx);
 * console.log(response.text());
 *
 * // Continue the conversation
 * const followUp = await response.resume(ctx, 'Tell me more');
 * ```
 */
export class ContextResponse<DepsT = unknown> extends BaseResponse {
  constructor(init: ContextResponseInit) {
    super(init);
  }

  /**
   * Generate a new ContextResponse using this response's messages with additional user content.
   *
   * Uses this response's tools and format type. Also uses this response's provider,
   * model, and params.
   *
   * @param ctx - A Context with the required deps type.
   * @param content - The new user message content to append to the message history.
   * @returns A new ContextResponse instance generated from the extended message history.
   *
   * @example
   * ```typescript
   * const response = await myPrompt(model, ctx);
   * console.log(response.text());
   *
   * // Continue the conversation
   * const followUp = await response.resume(ctx, 'Tell me more about that');
   * console.log(followUp.text());
   * ```
   */
  async resume(
    ctx: Context<DepsT>,
    content: UserContent
  ): Promise<ContextResponse<DepsT>> {
    const model = await this.model;
    return model.contextResume(ctx, this, content);
  }

  /**
   * Generate a new ContextStreamResponse using this response's messages with additional user content.
   *
   * Uses this response's tools and format type. Also uses this response's provider,
   * model, and params. Returns a streaming response for incremental consumption.
   *
   * @param ctx - A Context with the required deps type.
   * @param content - The new user message content to append to the message history.
   * @returns A new ContextStreamResponse instance generated from the extended message history.
   *
   * @example
   * ```typescript
   * const response = await myPrompt(model, ctx);
   * console.log(response.text());
   *
   * // Continue the conversation with streaming
   * const followUp = await response.resumeStream(ctx, 'Tell me more about that');
   * for await (const text of followUp.textStream()) {
   *   process.stdout.write(text);
   * }
   * ```
   */
  async resumeStream(
    ctx: Context<DepsT>,
    content: UserContent
  ): Promise<ContextStreamResponse<DepsT>> {
    const model = await this.model;
    return model.contextResumeStream(ctx, this, content);
  }

  // Note: execute_tools() method is not implemented yet as it requires Tools infrastructure.
}
