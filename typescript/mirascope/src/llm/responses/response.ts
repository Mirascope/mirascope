/**
 * Response class for LLM calls.
 */

import {
  BaseResponse,
  type BaseResponseInit,
} from '@/llm/responses/base-response';

/**
 * Initialization options for creating a Response.
 *
 * Currently identical to BaseResponseInit. When tools are implemented,
 * this will add additional fields like `tools` and `format`.
 */
export type ResponseInit = BaseResponseInit;

/**
 * The response generated by an LLM.
 *
 * This is the primary response class for non-streaming LLM calls. Since TypeScript
 * IO is always async, this single class handles all async response scenarios.
 *
 * @example
 * ```typescript
 * const response = await model.call([user("Hello!")]);
 * console.log(response.text());
 * ```
 */
export class Response extends BaseResponse {
  constructor(init: ResponseInit) {
    super(init);
    // Note: When tools are implemented, this will wrap tools in a Toolkit:
    // this.toolkit = tools instanceof Toolkit ? tools : new Toolkit(tools);
  }

  // Note: execute_tools() method is not implemented yet as it requires Tools infrastructure.
  // Note: resume() method is not implemented yet as it requires Model infrastructure.
}
