/**
 * Base interface for all LLM responses.
 */

import type {
  AssistantContentPart,
  Text,
  Thought,
  ToolCall,
} from '@/llm/content';
import type { Message } from '@/llm/messages';
import type { Params } from '@/llm/models';
import type { ModelId, ProviderId } from '@/llm/providers';
import type { FinishReason } from '@/llm/responses/finish-reason';
import type { Usage } from '@/llm/responses/usage';

/**
 * Base class for LLM responses.
 *
 * This abstract class defines the core interface that all response types must implement.
 * It provides the common properties and methods shared across all response variants.
 */
export abstract class RootResponse {
  /**
   * The raw response from the LLM.
   */
  abstract readonly raw: unknown;

  /**
   * The provider that generated this response.
   */
  abstract readonly providerId: ProviderId;

  /**
   * The model ID that generated this response.
   */
  abstract readonly modelId: ModelId;

  /**
   * Provider-specific model name (may include additional info like API mode).
   */
  abstract readonly providerModelName: string;

  /**
   * The parameters used to generate this response.
   */
  abstract readonly params: Params;

  /**
   * The message history, including the most recent assistant message.
   */
  abstract readonly messages: readonly Message[];

  /**
   * The content generated by the LLM.
   */
  abstract readonly content: readonly AssistantContentPart[];

  /**
   * The text content in the generated response, if any.
   */
  abstract readonly texts: readonly Text[];

  /**
   * The tools the LLM wants called on its behalf, if any.
   */
  abstract readonly toolCalls: readonly ToolCall[];

  /**
   * The readable thoughts from the model's thinking process, if any.
   *
   * The thoughts may be direct output from the model thinking process, or may be a
   * generated summary. (This depends on the provider; newer models tend to summarize.)
   */
  abstract readonly thoughts: readonly Thought[];

  /**
   * The reason why the LLM finished generating a response, if set.
   *
   * `finishReason` is only set if the response did not finish generating normally,
   * e.g. `FinishReason.MAX_TOKENS` if the model ran out of tokens before completing.
   * When the response generates normally, `response.finishReason` will be `null`.
   */
  abstract readonly finishReason: FinishReason | null;

  /**
   * Token usage statistics for this response, if available.
   */
  abstract readonly usage: Usage | null;

  /**
   * Return all text content from this response as a single string.
   *
   * Joins the text from all `Text` parts in the response content using the
   * specified separator.
   *
   * @param sep - The separator to use when joining multiple text parts.
   *              Defaults to newline ("\n").
   * @returns A string containing all text content joined by the separator.
   *          Returns an empty string if the response contains no text parts.
   *
   * @example
   * ```typescript
   * response.text()        // Join with newlines (default): "Hello\nWorld"
   * response.text(" ")     // Join with spaces: "Hello World"
   * response.text("")      // Concatenate directly: "HelloWorld"
   * ```
   */
  text(sep: string = '\n'): string {
    return this.texts.map((t) => t.text).join(sep);
  }

  /**
   * Return a string representation of all response content.
   *
   * The response content will be represented in a way that emphasizes clarity and
   * readability, but may not include all metadata (like thinking signatures or tool
   * call ids), and thus cannot be used to reconstruct the response.
   *
   * @example
   * ```
   * **Thinking:**
   *   The user is asking a math problem. I should use the calculator tool.
   *
   * **ToolCall (calculator):** {"operation": "mult", "a": 1337, "b": 4242}
   *
   * I am going to use the calculator and answer your question for you!
   * ```
   */
  pretty(): string {
    const parts: string[] = [];

    for (const part of this.content) {
      if (part.type === 'text') {
        parts.push(part.text);
      } else if (part.type === 'tool_call') {
        parts.push(`**ToolCall (${part.name}):** ${part.args}`);
      } else if (part.type === 'thought') {
        const indented = part.thought
          .split('\n')
          .map((line) => `  ${line}`)
          .join('\n');
        parts.push(`**Thinking:**\n${indented}`);
      }
    }

    return parts.join('\n\n');
  }

  // Note: parse() method is not implemented yet as it requires Format infrastructure.
  // Note: model property is not implemented yet as it requires Model infrastructure.
}
