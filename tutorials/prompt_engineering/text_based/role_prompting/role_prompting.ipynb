{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ef533fa10f438f",
   "metadata": {},
   "source": [
    "# Role Prompting\n",
    "\n",
    "[Role prompting](https://arxiv.org/pdf/2311.10054) is a commonly used prompt engineering technique where responses can be improved by setting the roles of the LLM or the audience within the conversation. The paper linked above showcases some analytics for which roles perform best for specific tasks. Role prompting can improve response quality in both accuracy based and open ended tasks.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Mirascope Concepts Used</p>\n",
    "<ul>\n",
    "<li><a href=\"../../../../learn/prompts/\">Prompts</a></li>\n",
    "<li><a href=\"../../../../learn/calls/\">Calls</a></li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a734e0ac2dc6c32f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T02:27:46.636320Z",
     "start_time": "2024-10-02T02:27:43.977430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the square root of the expression \\( x^2 + 2x + 1 \\), we can first recognize that this expression can be factored.\n",
      "\n",
      "The expression \\( x^2 + 2x + 1 \\) is a perfect square trinomial, and it can be factored as:\n",
      "\n",
      "\\[\n",
      "(x + 1)^2\n",
      "\\]\n",
      "\n",
      "Now, we can take the square root of this expression:\n",
      "\n",
      "\\[\n",
      "\\sqrt{x^2 + 2x + 1} = \\sqrt{(x + 1)^2}\n",
      "\\]\n",
      "\n",
      "Taking the square root of a square gives us the absolute value:\n",
      "\n",
      "\\[\n",
      "\\sqrt{(x + 1)^2} = |x + 1|\n",
      "\\]\n",
      "\n",
      "So, the final result is:\n",
      "\n",
      "\\[\n",
      "\\sqrt{x^2 + 2x + 1} = |x + 1|\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "from mirascope.core import openai, prompt_template\n",
    "\n",
    "\n",
    "@openai.call(model=\"gpt-4o-mini\")\n",
    "@prompt_template(\"\"\"\n",
    "    SYSTEM: {llm_role} {audience}\n",
    "    USER: {query}\n",
    "    \"\"\")\n",
    "def call(\n",
    "    query: str, llm_role: str | None = None, audience: str | None = None\n",
    ") -> openai.OpenAIDynamicConfig:\n",
    "    return {\n",
    "        \"computed_fields\": {\n",
    "            \"llm_role\": f\"You are {llm_role}.\" if llm_role else \"\",\n",
    "            \"audience\": f\"You are talking to {audience}.\" if audience else \"\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "response = call(\n",
    "    query=\"What's the square root of x^2 + 2x + 1?\",\n",
    "    llm_role=\"a math teacher\",\n",
    "    audience=\"your student\",\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcbba4f6c25bb4b",
   "metadata": {},
   "source": [
    "In this example, we're using role prompting to set the LLM's role as a math teacher and the audience as a student. This context can help the LLM tailor its response to be more educational and easier to understand, as a teacher would explain to a student.\n",
    "\n",
    "## Benefits of Role Prompting\n",
    "\n",
    "1. **Contextual Responses**: By setting roles, the LLM can provide responses that are more appropriate for the given context.\n",
    "2. **Improved Accuracy**: For certain tasks, setting the right role can lead to more accurate or relevant information.\n",
    "3. **Tailored Language**: The LLM can adjust its language and explanation style based on the roles, making responses more suitable for the intended audience.\n",
    "4. **Enhanced Creativity**: For open-ended tasks, role prompting can lead to more diverse and creative responses.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Effective Role Prompting</p>\n",
    "<ul>\n",
    "<li><strong>Choose Relevant Roles</strong>: Select roles that are appropriate for the task or query at hand.</li>\n",
    "<li><strong>Be Specific</strong>: The more specific you are about the roles, the better the LLM can tailor its response.</li>\n",
    "<li><strong>Experiment</strong>: Try different role combinations to see which produces the best results for your specific use case.</li>\n",
    "<li><strong>Consider the Audience</strong>: Setting an audience role can be just as important as setting the LLM's role.</li>\n",
    "<li><strong>Combine with Other Techniques</strong>: Role prompting can be used in conjunction with other prompt engineering techniques for even better results.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "By leveraging role prompting, you can guide the LLM to provide responses that are more aligned with your specific needs and context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
