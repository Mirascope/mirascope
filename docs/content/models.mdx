---
title: Models
description: Learn how to use the llm.Model class to send messages and get responses from LLMs.
---

<Info>
Reference: This doc should draw from:
- index.mdx "The Model Class" section
- python/mirascope/llm/model.py
</Info>

# Models

This document covers the `llm.Model` class for interacting with LLMs.

## Topics Covered

- Basic usage of `llm.Model` to send messages and get responses
- The `provider/model` string format (e.g., `"openai/gpt-4o"`)
- Creating model instances
- Sending messages with `model.run()`
- Streaming with `model.stream()`
- Model parameters and configuration
