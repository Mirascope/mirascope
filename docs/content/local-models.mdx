---
title: Local Models
description: Learn how to use local models with Mirascope via Ollama, vLLM, and other local providers.
---

<Info>
Reference: This doc should draw from:
- legacy/legacy-content-v1/local_models.mdx (Ollama, vLLM, local model setup)
- index.mdx "Using Local Models" section
</Info>

# Local Models

This document covers using local models with Mirascope.

## Topics Covered

- Using local models with Ollama
- Using MLX models on Apple Silicon
- Setting up vLLM for local inference
- Configuring base URLs for local endpoints
- Performance considerations for local models
