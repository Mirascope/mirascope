---
title: Quickstart
description: A quickstart guide to Mirascope's core patterns
---

# Mirascope Quickstart

<div className="badge-container">
    <a href="https://github.com/Mirascope/mirascope/actions/workflows/tests.yml" target="_blank"><img src="https://github.com/Mirascope/mirascope/actions/workflows/tests.yml/badge.svg?branch=main" alt="Tests"/></a>
    <a href="https://app.codecov.io/github/Mirascope/mirascope" target="_blank"><img src="https://codecov.io/github/Mirascope/mirascope/graph/badge.svg?token=HAEAWT3KC9" alt="Coverage"/></a>
    <a href="https://pypi.org/project/mirascope/" target="_blank"><img src="https://img.shields.io/pypi/v/mirascope.svg" alt="PyPI Version"/></a>
    <a href="https://pypi.org/project/mirascope/" target="_blank"><img src="https://img.shields.io/pypi/pyversions/mirascope.svg" alt="Stars"/></a>
    <a href="https://github.com/Mirascope/mirascope/blob/main/LICENSE"><img src="https://img.shields.io/github/license/Mirascope/mirascope.svg" alt="License"/></a>
</div>

Mirascope is a Python library for building LLM-powered applications. It provides type-safe, provider-agnostic abstractions that make it easy to call LLMs, use tools, and get structured output. 

## Installation

<TabbedSection>
<Tab value="uv">
```bash
uv add "mirascope[all]"
```
</Tab>
<Tab value="pip">
```bash
pip install "mirascope[all]"
```
</Tab>
</TabbedSection>

<Info title="Setting Up API Keys" collapsible={true} defaultOpen={false}>

To run any of the LLM-powered examples, you'll need to set up API keys. The easiest way is to sign up for [Mirascope Router](/cloud) and get a Mirascope API key. This single key works for multiple providers, including Anthropic, Google, and OpenAI.

Alternatively, set the API key for your chosen provider:

| Provider | Environment Variable |
| --- | --- |
| Anthropic | `ANTHROPIC_API_KEY` |
| Google | `GOOGLE_API_KEY` |
| Mirascope | `MIRASCOPE_API_KEY` |
| OpenAI | `OPENAI_API_KEY` |
| Together | `TOGETHER_API_KEY` |

Export your key in your shell so all examples run as written:

```bash
export OPENAI_API_KEY="your-api-key"
```

Or use a `.env` file with `python-dotenv`:

```python
from dotenv import load_dotenv

load_dotenv()  # Loads variables from .env file
```

See [Providers](/docs/llm/providers) for the full list of providers and configuration options.

</Info>

## Calling Models

The simplest way to call an LLM is with `llm.Model`. Specify a model ID in the format `"provider/model-name"` and call it with your content:

<CodeExample file="python/examples/models/basic.py" />

See [Models](/docs/llm/models) for parameters, model overrides, and more.

## Prompts

The `@llm.prompt` decorator creates reusable prompt functions. You write a function that returns the content to send, and the decorator handles the rest:

<CodeExample file="python/examples/prompts/basic.py" />

See [Prompts](/docs/llm/prompts) for return types, multimodal content, and more.

## Calls

The `@llm.call` decorator bundles a model with your prompt function for a more convenient API:

<CodeExample file="python/examples/calls/basic.py" />

See [Calls](/docs/llm/calls) for runtime overrides, parameters, and more.

## Continuing Conversations

Every response contains the full message history. Use `response.resume()` to continue the conversation:

<CodeExample file="python/examples/responses/resume.py" lines="3-" />

See [Responses](/docs/llm/responses) for content access, metadata, and more.

## Tools

Tools let LLMs request function calls. Define tools with `@llm.tool`, pass them to your call, then loop until done:

<TabbedSection>
<Tab value="Call">
<CodeExample file="python/examples/tools/with_call.py" />
</Tab>
<Tab value="Prompt">
<CodeExample file="python/examples/tools/with_prompt.py" />
</Tab>
<Tab value="Model">
<CodeExample file="python/examples/tools/with_model.py" />
</Tab>
</TabbedSection>

See [Tools](/docs/llm/tools) for async tools, parallel execution, and more.

## Structured Output

Use the `format` parameter to get typed responses. Mirascope supports primitives, enums, and Pydantic models:

<TabbedSection>
<Tab value="Call">
<CodeExample file="python/examples/structured_output/basic_call.py" />
</Tab>
<Tab value="Prompt">
<CodeExample file="python/examples/structured_output/basic_prompt.py" />
</Tab>
<Tab value="Model">
<CodeExample file="python/examples/structured_output/basic_model.py" />
</Tab>
</TabbedSection>

See [Structured Output](/docs/llm/structured-output) for formatting modes, validation, and more.

## Streaming

Call `.stream()` to get responses as they're generated:

<TabbedSection>
<Tab value="Call">
<CodeExample file="python/examples/streaming/basic_call.py" />
</Tab>
<Tab value="Prompt">
<CodeExample file="python/examples/streaming/basic_prompt.py" />
</Tab>
<Tab value="Model">
<CodeExample file="python/examples/streaming/basic_model.py" />
</Tab>
</TabbedSection>

See [Streaming](/docs/llm/streaming) for stream iterators, accumulated content, and more.

## Async

Make any prompt function async for concurrent operations:

<TabbedSection>
<Tab value="Call">
<CodeExample file="python/examples/async/basic.py" />
</Tab>
<Tab value="Prompt">
<CodeExample file="python/examples/async/basic_prompt.py" />
</Tab>
<Tab value="Model">
<CodeExample file="python/examples/async/basic_model.py" />
</Tab>
</TabbedSection>

See [Async](/docs/llm/async) for parallel calls, async tools, and more.

## Learning More 

If you'd like to learn more about Mirascope, consider the following resources:

- Read all of the focused topic guides that you'll find in these docs. They are organized so you can read them top to bottom, starting with [messages](/docs/llm/messages)
- We have extensive [end-to-end snapshot testing](https://github.com/Mirascope/mirascope/tree/v2/python/tests/e2e) which consists of real runnable Mirascope code, and snapshots that serialize the expected output. For example, here are [end to end tests for cross-provider thinking support](https://github.com/Mirascope/mirascope/blob/v2/python/tests/e2e/output/test_call_with_thinking_true.py) and [here are the corresponding snapshots](https://github.com/Mirascope/mirascope/tree/v2/python/tests/e2e/output/snapshots/test_call_with_thinking_true).
- The [API reference](/docs/api) documents all of the public functionality in Mirascope.
- You can hop on our [Discord](/discord-invite) and ask us questions directly!

We welcome your feedback, questions, and bug reports.
